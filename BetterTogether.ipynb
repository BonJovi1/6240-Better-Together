{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BetterTogether6240",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Pre-processing\n",
        "\n",
        "### Source\n",
        "https://snap.stanford.edu/data/cit-HepTh.html\n",
        "\n",
        "- Contains edge list, temporal data for each node, and text metadata for each node\n",
        "- First two are saved as single text files with a line for each edge or node respectively\n",
        "- Third includes a text file in .abs format for each node\n",
        "\n",
        "## Cleaning required:\n",
        "- Text extraction (including opening file format) - write to a text file for each year?\n",
        "- Embedding creation from extracted text\n",
        "\n",
        "### Graph Creation\n",
        "- Split edge list and extracted as a Python list of tuples (from edge 0 to edge 1) which was used to create a graph object using the NetworkX library\n",
        "\n",
        "### Text Extraction and Embedding Creation\n",
        "- Each paper had a separate text file containing description data (title, number of pages of comments, author email, the journal name, associated date/time of publication, occassionally subject) of varying length\n",
        "- Read data by line and created a string for each paper containing just the abstract\n",
        "- Wrote to a single text file containing the abstract for each paper on a separate line\n",
        "\n",
        "### Why dataset is sufficient\n",
        "\n",
        "### Data statistics\n",
        "- Number of edges: 352808\n",
        "- Number of valid edges: 352807\n",
        "- Number of nodes: 27770 (documents)\n",
        "- All available on Stanford website which is nice"
      ],
      "metadata": {
        "id": "D1jDyMKWiMBB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJgXVqu1xg6u",
        "outputId": "766de602-6eaa-4d03-90c4-631225822b73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_dir = 'drive/MyDrive/GaTechHw/CSE6240/Project/citationDataset/'"
      ],
      "metadata": {
        "id": "0SFAcaK7yW4w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_fp = 'Cit-HepTh.txt'"
      ],
      "metadata": {
        "id": "Lnq1utyACS3f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_abs = '9201001.abs'"
      ],
      "metadata": {
        "id": "8RRxHkaoyqpY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "y812q28eywJm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text File Processing\n",
        "\n",
        "Use the function below to extract text from a single .abs file."
      ],
      "metadata": {
        "id": "ojDuUsFRQxdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(file):\n",
        "    lines = file.split('\\n')\n",
        "    sep_count = 0\n",
        "    text = ''\n",
        "    for i in range(len(lines)):\n",
        "        if lines[i] == '\\\\\\\\':\n",
        "            sep_count += 1\n",
        "            continue\n",
        "        if sep_count == 2:\n",
        "            text += lines[i] + ' '\n",
        "    text = str.strip(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "rqXdoqCN0Tuh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract text for a folder of documents and write to a single text file."
      ],
      "metadata": {
        "id": "p8V3S5u7TKlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abs_folder = 'cit-HepTh-abstracts/'"
      ],
      "metadata": {
        "id": "JpzkYqaNyd5s"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "years = ['1992','1993','1994','1995', '1996','1997','1998','1999',\n",
        "         '2000','2001','2002','2003']"
      ],
      "metadata": {
        "id": "RyuTQVyqjO0_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_fp = 'abs_text.txt'"
      ],
      "metadata": {
        "id": "nj5ih44rkD-U"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = []\n",
        "node_file_list = []\n",
        "\n",
        "for folder in years:\n",
        "    file_list = os.listdir(project_dir + abs_folder + folder + '/')\n",
        "\n",
        "    for file in file_list:\n",
        "        fp = project_dir + abs_folder + folder + '/' + file\n",
        "        with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
        "            file_text = f.read()\n",
        "            extracted_text = extract_text(file_text)\n",
        "            text_list.append(extracted_text)\n",
        "    \n",
        "    for file in file_list:\n",
        "        node = file[:-4]\n",
        "        node_file_list.append(node)"
      ],
      "metadata": {
        "id": "C9-P1z6Uzn3S"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text_list))\n",
        "\n",
        "print(len(node_file_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFB22jWjvBNj",
        "outputId": "fa01366f-8aea-43d9-ac6f-788ceb0d79e4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29555\n",
            "29555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(save_fp, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i in range(len(text_list)):\n",
        "        f.write(node_file_list[i] + '\\t' + text_list[i] + '\\n')"
      ],
      "metadata": {
        "id": "dVUqunDDvRPJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edge List Processing"
      ],
      "metadata": {
        "id": "qJ8r8RzEMfO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edge_list = []\n",
        "with open(project_dir + node_fp, \"r\", encoding=\"utf-8\") as f:\n",
        "    node_txt = f.read()\n",
        "    edge_list = node_txt.split('\\n')\n",
        "print(edge_list[0:10])"
      ],
      "metadata": {
        "id": "fHM9nIK8zRlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = []\n",
        "for edge in edge_list[4:]:\n",
        "    from_to = edge.split('\\t')\n",
        "    try:\n",
        "      from_to = (int(from_to[0]), int(from_to[1]))\n",
        "    except:\n",
        "      continue\n",
        "    edges.append(from_to)"
      ],
      "metadata": {
        "id": "8ZcvD_O3D-ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(edges))"
      ],
      "metadata": {
        "id": "U6cUqdcZExp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(edges[:10])"
      ],
      "metadata": {
        "id": "ZQMi91GVFd4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx"
      ],
      "metadata": {
        "id": "GWORAlrNFNZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.DiGraph()"
      ],
      "metadata": {
        "id": "8FSmxVWjFO14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.add_edges_from(edges)"
      ],
      "metadata": {
        "id": "W4oST-l4FSfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9GZfG6znzctv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}