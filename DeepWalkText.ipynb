{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DeepWalk and Text Baseline Models"
      ],
      "metadata": {
        "id": "hGh419sKnyXi"
      },
      "id": "hGh419sKnyXi"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install dgl dglgo -f https://data.dgl.ai/wheels/repo.html\n",
        "# !pip install dgl-cu101\n",
        "!pip install dgl-cu101 dglgo -f https://data.dgl.ai/wheels/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzoD0fOfk-Cd",
        "outputId": "d7a143cb-4019-4375-c492-3bc5f4fa391d"
      },
      "id": "JzoD0fOfk-Cd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl-cu101\n",
            "  Downloading https://data.dgl.ai/wheels/dgl_cu101-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (150.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 150.0 MB 8.6 kB/s \n",
            "\u001b[?25hCollecting dglgo\n",
            "  Downloading dglgo-0.0.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (4.64.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (3.0.4)\n",
            "Collecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 9.8 MB/s \n",
            "\u001b[?25hCollecting autopep8>=1.6.0\n",
            "  Downloading autopep8-1.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml>=0.17.20\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 48.4 MB/s \n",
            "\u001b[?25hCollecting numpydoc>=1.1.0\n",
            "  Downloading numpydoc-1.2.1-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 218 kB/s \n",
            "\u001b[?25hCollecting pydantic>=1.9.0\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 44.2 MB/s \n",
            "\u001b[?25hCollecting typer>=0.4.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting isort>=5.10.1\n",
            "  Downloading isort-5.10.1-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 48.7 MB/s \n",
            "\u001b[?25hCollecting pycodestyle>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 706 kB/s \n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: Jinja2<3.1,>=2.10 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=1.1.0->dglgo) (2.11.3)\n",
            "Requirement already satisfied: sphinx>=1.8 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=1.1.0->dglgo) (1.8.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.1,>=2.10->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.9.0->dglgo) (4.2.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (0.17.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (21.3)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (2.9.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (57.4.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (2.6.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (1.2.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (1.15.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.8->numpydoc>=1.1.0->dglgo) (0.7.12)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->sphinx>=1.8->numpydoc>=1.1.0->dglgo) (2022.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer>=0.4.0->dglgo) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=1.8->numpydoc>=1.1.0->dglgo) (3.0.8)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.8->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Installing collected packages: toml, ruamel.yaml.clib, pycodestyle, typer, ruamel.yaml, PyYAML, pydantic, numpydoc, isort, autopep8, dglgo, dgl-cu101\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 autopep8-1.6.0 dgl-cu101-0.8.1 dglgo-0.0.1 isort-5.10.1 numpydoc-1.2.1 pycodestyle-2.8.0 pydantic-1.9.0 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.6 toml-0.10.2 typer-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "278ccfe8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "278ccfe8",
        "outputId": "aaac5ac3-ea09-4aba-99bb-0355e591d55a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe6735aa430>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import torch \n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import dgl\n",
        "import random\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, roc_auc_score\n",
        "#Seeds\n",
        "dgl.seed(42)\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d318bbcd",
      "metadata": {
        "id": "d318bbcd"
      },
      "outputs": [],
      "source": [
        "PATH_TO_GRAPH_FILE = \"cit-HepTh.txt\"\n",
        "graphAdjList = []\n",
        "with open(PATH_TO_GRAPH_FILE, 'r') as f:\n",
        "    L = f.readlines()\n",
        "    for line_ in L:\n",
        "        if \"#\" in line_:\n",
        "            continue \n",
        "        src, dst = map(lambda x: int(x), line_.strip().split('\\t'))\n",
        "        graphAdjList.append([src,dst])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8777bedc",
      "metadata": {
        "id": "8777bedc"
      },
      "source": [
        "### Loading Data into NetworkX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "300ec4b9",
      "metadata": {
        "id": "300ec4b9"
      },
      "outputs": [],
      "source": [
        "nx_g = nx.DiGraph()\n",
        "nx_g.add_edges_from(graphAdjList)\n",
        "\n",
        "paper_to_node = {node:index for index, node in enumerate(sorted(nx_g.nodes())) }\n",
        "node_to_paper = {v:k for k, v in paper_to_node.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b39acb56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b39acb56",
        "outputId": "e9920e04-c3f5-44be-eecd-f7d8dfe43d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "73c86899",
      "metadata": {
        "id": "73c86899"
      },
      "outputs": [],
      "source": [
        "g = dgl.from_networkx(nx_g).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9eb0760d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eb0760d",
        "outputId": "57f8db47-8978-4c9b-ff7c-61126040ce49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_size: 317527, test_size: 35280\n"
          ]
        }
      ],
      "source": [
        "# Split edge set for training and testing\n",
        "u, v = g.edges()\n",
        "\n",
        "eids = np.arange(g.number_of_edges())\n",
        "eids = np.random.permutation(eids)\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.number_of_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "print(\"train_size: {}, test_size: {}\".format(train_size, test_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e549ea3f",
      "metadata": {
        "id": "e549ea3f"
      },
      "outputs": [],
      "source": [
        "# Find all negative edges and split them for training and testing\n",
        "neg_u, neg_v = dgl.sampling.global_uniform_negative_sampling(g, g.number_of_edges())\n",
        "test_neg_u, test_neg_v = neg_u[:test_size], neg_v[:test_size]\n",
        "train_neg_u, train_neg_v = neg_u[test_size:], neg_v[test_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a4bf1307",
      "metadata": {
        "id": "a4bf1307"
      },
      "outputs": [],
      "source": [
        "# Removing test edges from graph\n",
        "train_g = dgl.remove_edges(g, eids[:test_size])\n",
        "nx_train_g = dgl.to_networkx(train_g.cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7bcd538d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bcd538d",
        "outputId": "3c57856a-37e9-4b58-dbc0-9a5dac61c49c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 27770, Number of edges: 317527\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of nodes: {}, Number of edges: {}\".format(nx_train_g.number_of_nodes(), nx_train_g.number_of_edges()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ede6a57e",
      "metadata": {
        "id": "ede6a57e"
      },
      "source": [
        "### Train Deepwalk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8e08174f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e08174f",
        "outputId": "02dedae6-5b9e-4c00-b974-bdd1375591d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting install\n",
            "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
            "Collecting karateclub\n",
            "  Downloading karateclub-1.2.3.tar.gz (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 534 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.21.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from karateclub) (2.6.3)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from karateclub) (4.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from karateclub) (4.64.0)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from karateclub) (0.16)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.4.1)\n",
            "Collecting pygsp\n",
            "  Downloading PyGSP-0.5.1-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 11.1 MB/s \n",
            "\u001b[?25hCollecting gensim>=4.0.0\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.15.0)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->karateclub) (5.2.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->karateclub) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->karateclub) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->karateclub) (57.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->karateclub) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->karateclub) (3.1.0)\n",
            "Building wheels for collected packages: karateclub, python-Levenshtein\n",
            "  Building wheel for karateclub (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for karateclub: filename=karateclub-1.2.3-py3-none-any.whl size=97754 sha256=bedc4e0e093f1128731ae9b3321c211d65cfbc2977621dd124bef019d4f833a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/09/80/0d50455fd4e297e88f8f38a711c6f4849e6bd1a330000dde3d\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149860 sha256=814b2539037d466b9bb518420c8479ccfeb3483cbcf44e1059fc39369f007884\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built karateclub python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, pygsp, gensim, karateclub, install\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.1.2 install-1.3.5 karateclub-1.2.3 pygsp-0.5.1 python-Levenshtein-0.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install install karateclub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from karateclub import DeepWalk, Node2Vec"
      ],
      "metadata": {
        "id": "FECo2K_GpnEJ"
      },
      "id": "FECo2K_GpnEJ",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1e5a353f",
      "metadata": {
        "id": "1e5a353f"
      },
      "outputs": [],
      "source": [
        "# node2id = {node:i for i, node in enumerate(sorted(nx_g.nodes()))}\n",
        "node2id = {node:i for i, node in enumerate(sorted(nx_g.nodes()))}\n",
        "id2node = {v:k for k, v in paper_to_node.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ee855f3d",
      "metadata": {
        "id": "ee855f3d"
      },
      "outputs": [],
      "source": [
        "model = DeepWalk()\n",
        "# model = Node2Vec()\n",
        "model.fit(nx_train_g)\n",
        "node_embedding = model.get_embedding()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6c89b0d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c89b0d5",
        "outputId": "cfd1b982-e1b7-42a7-851d-90927e4eef02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node Embedding Shape: (27770, 128)\n"
          ]
        }
      ],
      "source": [
        "print(\"Node Embedding Shape: {}\".format(node_embedding.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt('deepwalk_embeddings.txt', node_embedding)"
      ],
      "metadata": {
        "id": "W4-1ajEDqVzq"
      },
      "id": "W4-1ajEDqVzq",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "abdda301",
      "metadata": {
        "id": "abdda301"
      },
      "source": [
        "### Get Text Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown &> /dev/null\n",
        "!gdown 1OxLLkPAeaC10Q3Ko-WN74ov_4zhmoPff\n",
        "# https://drive.google.com/file/d/1OxLLkPAeaC10Q3Ko-WN74ov_4zhmoPff/view?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EviMU7KqkkhP",
        "outputId": "54cbe72f-76d0-415a-b36b-3c6f8097f71b"
      },
      "id": "EviMU7KqkkhP",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OxLLkPAeaC10Q3Ko-WN74ov_4zhmoPff\n",
            "To: /content/sentence_transformers_embeddings.pkl\n",
            "100% 47.6M/47.6M [00:00<00:00, 207MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "15705fd9",
      "metadata": {
        "id": "15705fd9"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "TEXT_EMBEDDING_FILE = \"sentence_transformers_embeddings.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "efc86247",
      "metadata": {
        "id": "efc86247"
      },
      "outputs": [],
      "source": [
        "with open(TEXT_EMBEDDING_FILE, 'rb') as f:\n",
        "    text_embeddings = pickle.load(f)\n",
        "text_embeddings = {int(k) : v for k, v in text_embeddings.items()} #Convert keys to integer values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec7a1c41",
      "metadata": {
        "id": "ec7a1c41"
      },
      "source": [
        "### PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3da29d72",
      "metadata": {
        "id": "3da29d72"
      },
      "outputs": [],
      "source": [
        "class CitationDataset(Dataset):\n",
        "    def __init__(self, graph, edges_u, edges_v, labels, node_embedding, text_embedding, node2id, id2node):\n",
        "        self.graph = graph\n",
        "        self.edges_u = edges_u\n",
        "        self.edges_v = edges_v\n",
        "        self.labels = labels\n",
        "        self.node2id = node2id\n",
        "        self.id2node = id2node\n",
        "        self.node_embedding = node_embedding\n",
        "        self.text_embedding = text_embedding\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.edges_u)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        u = self.edges_u[idx]\n",
        "        v = self.edges_v[idx]\n",
        "        node_u_emb = torch.tensor(self.node_embedding[u])\n",
        "        node_v_emb = torch.tensor(self.node_embedding[v])\n",
        "        \n",
        "        text_u_emb = torch.tensor(self.text_embedding[id2node[u.item()]])\n",
        "        text_v_emb = torch.tensor(self.text_embedding[id2node[v.item()]])\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        return node_u_emb, node_v_emb, text_u_emb, text_v_emb, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "fa43c5b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa43c5b8",
        "outputId": "faca02c1-5c65-43b3-ab77-7a6b36e85b53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([635054]),\n",
              " torch.Size([635054]),\n",
              " torch.Size([635054]),\n",
              " 'torch.LongTensor')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "train_u = torch.concat((train_pos_u, train_neg_u), dim=0)\n",
        "train_v = torch.concat((train_pos_v, train_neg_v), dim=0)\n",
        "train_label = torch.cat([torch.ones(train_pos_u.shape[0]), torch.zeros(train_neg_u.shape[0])])\n",
        "train_label = train_label.long()\n",
        "train_u.shape, train_v.shape, train_label.shape, train_label.type()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e6802815",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6802815",
        "outputId": "1ff63edb-ecbf-43ca-e749-fda5799ff158"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([70560]),\n",
              " torch.Size([70560]),\n",
              " torch.Size([70560]),\n",
              " 'torch.LongTensor')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "test_u = torch.concat((test_pos_u, test_neg_u), dim=0)\n",
        "test_v = torch.concat((test_pos_v, test_neg_v), dim=0)\n",
        "test_label = torch.cat([torch.ones(test_pos_u.shape[0]), torch.zeros(test_pos_v.shape[0])])\n",
        "test_label = test_label.long()\n",
        "test_u.shape, test_v.shape, test_label.shape, test_label.type()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4c4cd954",
      "metadata": {
        "id": "4c4cd954"
      },
      "outputs": [],
      "source": [
        "train_dataset = CitationDataset(nx_train_g, train_u, train_v, train_label, node_embedding, text_embeddings, node2id, id2node)\n",
        "test_dataset = CitationDataset(nx_g, test_u, test_v, test_label, node_embedding, text_embeddings, node2id, id2node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f0898169",
      "metadata": {
        "id": "f0898169"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c271c22",
      "metadata": {
        "id": "3c271c22"
      },
      "source": [
        "##### Dataset Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a22f3318",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a22f3318",
        "outputId": "0839b786-cdb4-4e74-8ffa-6e317c7ba3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node_u: torch.Size([256, 128]), node_v: torch.Size([256, 128])\n",
            "text_u: torch.Size([256, 384]), text_v: torch.Size([256, 384])\n",
            "label.size(): torch.Size([256])\n"
          ]
        }
      ],
      "source": [
        "for i, data in enumerate(train_loader):\n",
        "    node_u, node_v, text_u, text_v, label = data\n",
        "    print(\"node_u: {}, node_v: {}\".format(node_u.size(), node_v.size()))\n",
        "    print(\"text_u: {}, text_v: {}\".format(text_u.size(), text_v.size()))\n",
        "    print(\"label.size(): {}\".format(label.size()))\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Classes"
      ],
      "metadata": {
        "id": "32jvNB4TrlNM"
      },
      "id": "32jvNB4TrlNM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DeepWalk Embeddings"
      ],
      "metadata": {
        "id": "6QoOasvrrp-a"
      },
      "id": "6QoOasvrrp-a"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a0816821",
      "metadata": {
        "id": "a0816821"
      },
      "outputs": [],
      "source": [
        "class DeepWalkBaseline(nn.Module):\n",
        "    def __init__(self, node_emb_dim=128, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.node_emb_dim = node_emb_dim\n",
        "        self.linear1 = nn.Linear(2 * self.node_emb_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, 2)\n",
        "        self.activation = nn.ReLU()\n",
        "    \n",
        "    def forward(self, node_u, text_u, node_v, text_v):\n",
        "        node_combined = torch.cat((node_u, node_v), dim=1) # N x (2 * node_dim)\n",
        "        _out = self.activation(self.linear1(node_combined)) \n",
        "        _out = self.linear2(_out) # N x 2\n",
        "        return _out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Embeddings"
      ],
      "metadata": {
        "id": "Kv74npzDrrnn"
      },
      "id": "Kv74npzDrrnn"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2ea22e4b",
      "metadata": {
        "id": "2ea22e4b"
      },
      "outputs": [],
      "source": [
        "class TextBaseline(nn.Module):\n",
        "    def __init__(self, text_emb_dim=384, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.text_emb_dim = text_emb_dim\n",
        "        self.linear1 = nn.Linear(2 * self.text_emb_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, 2)\n",
        "        self.activation = nn.ReLU()\n",
        "    \n",
        "    def forward(self, node_u, text_u, node_v, text_v):\n",
        "        node_combined = torch.cat((text_u, text_v), dim=1) # N x (2 * text_dim)\n",
        "        _out = self.activation(self.linear1(node_combined)) \n",
        "        _out = self.linear2(_out) # N x 2\n",
        "        return _out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined Embeddings"
      ],
      "metadata": {
        "id": "JX4xpaqMrwLE"
      },
      "id": "JX4xpaqMrwLE"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "104f802f",
      "metadata": {
        "id": "104f802f"
      },
      "outputs": [],
      "source": [
        "# Node & Text Embedding Combined Model\n",
        "class NTEC(nn.Module):\n",
        "    def __init__(self, node_emb_dim=128, text_emb_dim=384, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.node_emb_dim = node_emb_dim        \n",
        "        self.text_emb_dim = text_emb_dim\n",
        "        self.linear1 = nn.Linear(2*(self.text_emb_dim + self.node_emb_dim), 128)\n",
        "        self.linear2 = nn.Linear(hidden_dim, 2)\n",
        "        self.activation = nn.ReLU()\n",
        "    \n",
        "    def forward(self, node_u, text_u, node_v, text_v):\n",
        "        node_combined = torch.cat((node_u, text_u, node_v, text_v), dim=1) # N x (2 * (node_dim + text_dim))\n",
        "        _out = self.activation(self.linear1(node_combined)) \n",
        "        _out = self.linear2(_out) # N x 2\n",
        "        return _out    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric Definition and Training Loop"
      ],
      "metadata": {
        "id": "V408-gdmry5r"
      },
      "id": "V408-gdmry5r"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e6894dea",
      "metadata": {
        "id": "e6894dea"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(preds, labels):\n",
        "    preds = np.array(preds)\n",
        "    labels = np.array(labels)\n",
        "    # roc_auc = roc_auc_score(labels, preds[:, 1])\n",
        "    roc_auc = 1\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds)\n",
        "    recall = recall_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds)\n",
        "    return roc_auc, acc, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "17207db1",
      "metadata": {
        "id": "17207db1"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, test_loader, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        pred_labels_epoch = []\n",
        "        true_labels_epoch = []\n",
        "        train_loss_epoch = 0.0\n",
        "        outs = []\n",
        "        # outs = np.array(outs)\n",
        "        for i, data in enumerate(train_loader):\n",
        "            # if i >= 5:\n",
        "            #     break\n",
        "          \n",
        "            node_u, node_v, text_u, text_v, label = data\n",
        "            node_u = node_u.to(device)\n",
        "            node_v = node_v.to(device)\n",
        "            text_u = text_u.to(device)\n",
        "            text_v = text_v.to(device)\n",
        "            label = label.to(device)\n",
        "            \n",
        "            out = model(node_u, text_u, node_v, text_v)\n",
        "            outs.extend(out[:, 1].detach().cpu().numpy())\n",
        "            preds = torch.argmax(out, dim=1)\n",
        "            loss = criterion(out, label)\n",
        "            train_loss_epoch += loss.item()\n",
        "            \n",
        "            pred_labels_epoch.extend(list(preds.detach().cpu().numpy()))\n",
        "            true_labels_epoch.extend(list(label.detach().cpu().numpy()))\n",
        "            \n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "                    \n",
        "        # Compute train metrics\n",
        "        roc_auc, acc, precision, recall, f1 = compute_metrics(pred_labels_epoch, true_labels_epoch)\n",
        "        outs = np.array(outs)\n",
        "        roc_auc = roc_auc_score(true_labels_epoch, outs)\n",
        "        print(\"TRAIN, Epoch number: \", epoch)\n",
        "        print(\"Num labels: {}\".format(len(pred_labels_epoch)))\n",
        "        print(\"Loss: {}\".format(train_loss_epoch / len(pred_labels_epoch)))\n",
        "        print(\"roc_auc: {}, acc: {}, precision: {}, recall: {}, f1: {}\".format(roc_auc, acc, precision, recall, f1))\n",
        "        evaluate(model, test_loader)\n",
        "        print(\"-\"*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Function"
      ],
      "metadata": {
        "id": "5vI-wY0Rr6Ll"
      },
      "id": "5vI-wY0Rr6Ll"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "9241957f",
      "metadata": {
        "id": "9241957f"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_labels_epoch = []\n",
        "        true_labels_epoch = []\n",
        "        outs = []        \n",
        "        for i, data in enumerate(dataloader):\n",
        "            node_u, node_v, text_u, text_v, label = data\n",
        "            \n",
        "            node_u, node_v, text_u, text_v, label = data\n",
        "            node_u = node_u.to(device)\n",
        "            node_v = node_v.to(device)\n",
        "            text_u = text_u.to(device)\n",
        "            text_v = text_v.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            out = model(node_u, text_u, node_v, text_v)\n",
        "            outs.extend(out[:, 1].detach().cpu().numpy())\n",
        "            preds = torch.argmax(out, dim=1)\n",
        "\n",
        "            pred_labels_epoch.extend(list(preds.detach().cpu().numpy()))\n",
        "            true_labels_epoch.extend(list(label.detach().cpu().numpy()))\n",
        "        \n",
        "        roc_auc, acc, precision, recall, f1 = compute_metrics(pred_labels_epoch, true_labels_epoch)\n",
        "        outs = np.array(outs)\n",
        "        roc_auc = roc_auc_score(true_labels_epoch, outs)\n",
        "        print(\"TEST\")\n",
        "        print(\"roc_auc: {}, acc: {}, precision: {}, recall: {}, f1: {}\".format(roc_auc, acc, precision, recall, f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec2a2ce5",
      "metadata": {
        "id": "ec2a2ce5"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "c5642591",
      "metadata": {
        "id": "c5642591"
      },
      "outputs": [],
      "source": [
        "model = DeepWalkBaseline()\n",
        "# model = TextBaseline()\n",
        "# model = NTEC()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "35f71ccc",
      "metadata": {
        "id": "35f71ccc"
      },
      "outputs": [],
      "source": [
        "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7cfd233",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7cfd233",
        "outputId": "36e99563-add5-4a3f-bdb3-c51d5e01a7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN, Epoch number:  0\n",
            "Num labels: 635054\n",
            "Loss: 0.0021814378612129556\n",
            "roc_auc: 0.7778319580734262, acc: 0.7132259618867057, precision: 0.7237530900101788, recall: 0.6897019780995002, f1: 0.7063173766156277\n",
            "TEST\n",
            "roc_auc: 0.7790869452703605, acc: 0.696797052154195, precision: 0.6921884515307535, recall: 0.7087868480725623, f1: 0.7003893230260761\n",
            "----------------------------------------------------------------------------------------------------\n",
            "TRAIN, Epoch number:  1\n",
            "Num labels: 635054\n",
            "Loss: 0.0019137103459948485\n",
            "roc_auc: 0.838812592627987, acc: 0.7537563734737518, precision: 0.7584412918456175, recall: 0.7446925773241331, f1: 0.7515040569014998\n",
            "TEST\n",
            "roc_auc: 0.7920679614910968, acc: 0.7231434240362812, precision: 0.7238095238095238, recall: 0.721655328798186, f1: 0.7227308210914769\n",
            "----------------------------------------------------------------------------------------------------\n",
            "TRAIN, Epoch number:  2\n",
            "Num labels: 635054\n",
            "Loss: 0.0018002767590903353\n",
            "roc_auc: 0.8612507700236458, acc: 0.7775921417706211, precision: 0.7945247133042851, recall: 0.7488465547811682, f1: 0.7710096806252928\n",
            "TEST\n",
            "roc_auc: 0.8126495996877587, acc: 0.7428713151927437, precision: 0.7510915750915751, recall: 0.7265022675736962, f1: 0.7385923204380088\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "train(model, train_loader, test_loader, num_epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "d6A0qCOHsJqW"
      },
      "id": "d6A0qCOHsJqW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db3fb265",
      "metadata": {
        "id": "db3fb265"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve, auc, RocCurveDisplay\n",
        "\n",
        "def compute_auc(pos_score, neg_score):\n",
        "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "    labels = torch.cat(\n",
        "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Link Prediction')\n",
        "    display.plot()\n",
        "    return roc_auc"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "DeepWalkText.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}